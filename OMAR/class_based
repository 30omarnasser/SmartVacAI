# YOLOv8 Transfer Learning System for Specific Waste Type Detection
# Modified to classify: plastic, trash, metal, paper, cardboard, glass, dirt
# Author: AI Team

import os
import cv2
import json
import time
import numpy as np
import requests
import zipfile
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import yaml
from datetime import datetime
import shutil

# Import YOLO from ultralytics
try:
    from ultralytics import YOLO
except ImportError:
    print("Installing ultralytics...")
    os.system("pip install ultralytics")
    from ultralytics import YOLO

# ============================================================================
# 1. MODIFIED TRASHNET DATASET PROCESSOR FOR SPECIFIC CLASSES
# ============================================================================

class SpecificTrashNetProcessor:
    """Downloads and processes TrashNet dataset for specific waste type classification"""
    
    def __init__(self, dataset_path: str = "./specific_trashnet_dataset"):
        self.dataset_path = Path(dataset_path)
        self.trashnet_url = "https://github.com/garythung/trashnet/archive/refs/heads/master.zip"
        
        # MODIFIED: Keep all original classes + add dirt
        self.final_classes = ['dirt', 'plastic', 'trash', 'metal', 'paper', 'cardboard', 'glass']
        
        # Class mapping - keep original names
        self.class_mapping = {
            'cardboard': 'cardboard',
            'glass': 'glass', 
            'metal': 'metal',
            'paper': 'paper',
            'plastic': 'plastic',
            'trash': 'trash'
        }
        
    def download_trashnet(self):
        """Use existing dataset or download TrashNet as fallback"""
        print("📥 Checking for existing TrashNet dataset...")
        
        # Use your existing dataset path
        source_path = Path(r"C:\Users\pc\Downloads\archive\dataset-resized")
        
        if not source_path.exists():
            print(f"❌ Existing dataset not found at {source_path}. Downloading TrashNet...")
            zip_path = self.dataset_path / "trashnet.zip"
            self.dataset_path.mkdir(exist_ok=True)
            
            if not zip_path.exists():
                response = requests.get(self.trashnet_url, stream=True)
                with open(zip_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                print("✅ Download completed!")
            
            # Extract
            if not (self.dataset_path / "trashnet-master").exists():
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extractall(self.dataset_path)
                print("✅ Extraction completed!")
            
            # Fallback to downloaded dataset path
            source_path = self.dataset_path / "trashnet-master" / "data" / "dataset-resized"
            if not source_path.exists():
                source_path = self.dataset_path / "trashnet-master" / "data"
        
        # Debug: List class folders and image counts
        print(f"Source path: {source_path}")
        class_folders = [f for f in source_path.iterdir() if f.is_dir()]
        print(f"Found {len(class_folders)} class folders: {[f.name for f in class_folders]}")
        
        total_images = 0
        for class_folder in class_folders:
            images = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:
                images.extend(list(class_folder.glob(ext)))
            print(f"  - {class_folder.name}: {len(images)} images")
            total_images += len(images)
        
        if total_images == 0:
            print("❌ No images found! Check extensions or folder contents.")
            return None
        
        print(f"✅ Total images across classes: {total_images}")
        return source_path
    
    def convert_to_yolo_format(self, source_path: Path):
        """Convert TrashNet to YOLO format with specific class mapping"""
        print("🔄 Converting TrashNet to YOLO format with specific classes...")
        
        # Create YOLO structure
        yolo_path = self.dataset_path / "yolo_format"
        for split in ['train', 'val', 'test']:
            (yolo_path / split / 'images').mkdir(parents=True, exist_ok=True)
            (yolo_path / split / 'labels').mkdir(parents=True, exist_ok=True)
        
        # Process each class folder
        image_count = 0
        label_count = 0
        class_distribution = {cls: 0 for cls in self.final_classes}
        
        for class_folder in source_path.iterdir():
            if not class_folder.is_dir():
                print(f"Skipping non-directory: {class_folder}")
                continue
                
            class_name = class_folder.name.lower()
            if class_name not in self.class_mapping:
                print(f"⚠️  Skipping unknown class: {class_name}")
                continue
            
            # MODIFIED: Use specific class names instead of generic 'waste'
            mapped_class = self.class_mapping[class_name]
            class_id = self.final_classes.index(mapped_class)
            
            # Support multiple case-insensitive extensions
            images = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:
                images.extend(list(class_folder.glob(ext)))
            
            print(f"Processing {class_name} -> {mapped_class} (ID: {class_id}): {len(images)} images")
            
            if not images:
                print(f"⚠️  No images found in {class_folder}. Skipping.")
                continue
            
            # Split images: 70% train, 20% val, 10% test
            train_count = int(len(images) * 0.7)
            val_count = int(len(images) * 0.2)
            
            splits = {
                'train': images[:train_count],
                'val': images[train_count:train_count + val_count],
                'test': images[train_count + val_count:]
            }
            
            for split, split_images in splits.items():
                print(f"  {split} split: {len(split_images)} images")
                for img_path in split_images:
                    new_img_name = f"{class_name}_{img_path.stem}_{image_count}.jpg"
                    new_img_path = yolo_path / split / 'images' / new_img_name
                    
                    img = cv2.imread(str(img_path))
                    if img is None:
                        print(f"  Failed to load: {img_path}")
                        continue
                        
                    cv2.imwrite(str(new_img_path), img)
                    
                    # Create label (full image = one object)
                    h, w = img.shape[:2]
                    label_path = yolo_path / split / 'labels' / f"{new_img_name.replace('.jpg', '.txt')}"
                    
                    with open(label_path, 'w') as f:
                        f.write(f"{class_id} 0.5 0.5 1.0 1.0\n")
                    
                    image_count += 1
                    label_count += 1
                    class_distribution[mapped_class] += 1
        
        print(f"✅ Conversion completed! {image_count} images, {label_count} labels")
        
        # Print class distribution
        print("\n📊 CLASS DISTRIBUTION:")
        print("=" * 40)
        for class_name, count in class_distribution.items():
            print(f"{class_name:<12}: {count:>6} images")
        
        if image_count == 0:
            print("❌ No images processed. Check the debug output above.")
            return None
        
        # Create dataset.yaml with all specific classes
        dataset_config = {
            'path': str(yolo_path.absolute()),
            'train': 'train/images',
            'val': 'val/images', 
            'test': 'test/images',
            'nc': len(self.final_classes),
            'names': self.final_classes
        }
        
        yaml_path = yolo_path / 'dataset.yaml'
        with open(yaml_path, 'w') as f:
            yaml.dump(dataset_config, f)
        
        print(f"📄 Dataset config saved to: {yaml_path}")
        print(f"📝 Classes: {self.final_classes}")
        return str(yaml_path)
    
    def add_dirt_images(self, dirt_images_folder: str):
        """Add dirt images to the dataset"""
        print("🌱 Adding dirt images...")
        
        dirt_path = Path(dirt_images_folder)
        if not dirt_path.exists():
            print("⚠️  Dirt images folder not found. Creating placeholder...")
            return
        
        yolo_path = self.dataset_path / "yolo_format"
        dirt_images = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:
            dirt_images.extend(list(dirt_path.glob(ext)))
        
        if not dirt_images:
            print("⚠️  No dirt images found. You'll need to add them manually.")
            return
        
        # Split dirt images across train/val/test
        train_count = int(len(dirt_images) * 0.7)
        val_count = int(len(dirt_images) * 0.2)
        
        splits = {
            'train': dirt_images[:train_count],
            'val': dirt_images[train_count:train_count + val_count],
            'test': dirt_images[train_count + val_count:]
        }
        
        dirt_class_id = 0  # 'dirt' is class 0
        image_count = 0
        
        for split, split_images in splits.items():
            for img_path in split_images:
                new_img_name = f"dirt_{img_path.stem}_{image_count}.jpg"
                new_img_path = yolo_path / split / 'images' / new_img_name
                
                img = cv2.imread(str(img_path))
                if img is None:
                    continue
                    
                cv2.imwrite(str(new_img_path), img)
                
                label_path = yolo_path / split / 'labels' / f"{new_img_name.replace('.jpg', '.txt')}"
                with open(label_path, 'w') as f:
                    f.write(f"{dirt_class_id} 0.5 0.5 1.0 1.0\n")
                
                image_count += 1
        
        print(f"✅ Added {image_count} dirt images to dataset")

# ============================================================================
# 2. ENHANCED DETECTOR FOR SPECIFIC WASTE CLASSIFICATION
# ============================================================================

class SpecificWasteDetector:
    """Enhanced detector for specific waste type classification"""
    
    def __init__(self, model_path: str, confidence_threshold: float = 0.5):
        self.model_path = model_path
        self.confidence_threshold = confidence_threshold
        
        # MODIFIED: Updated class list
        self.classes = ['dirt', 'plastic', 'trash', 'metal', 'paper', 'cardboard', 'glass']
        
        # Color mapping for visualization
        self.colors = {
            'dirt': (0, 255, 255),      # Yellow
            'plastic': (255, 0, 0),     # Blue
            'trash': (0, 0, 255),       # Red
            'metal': (128, 128, 128),   # Gray
            'paper': (255, 255, 255),   # White
            'cardboard': (0, 165, 255), # Orange
            'glass': (255, 0, 255)      # Magenta
        }
        
        try:
            self.model = YOLO(model_path)
            print(f"✅ Specific waste classification model loaded from {model_path}")
        except Exception as e:
            print(f"❌ Error loading model: {e}")
            self.model = None
    
    def detect_specific_waste(self, frame: np.ndarray) -> Dict:
        """Detect specific waste types with detailed classification"""
        if self.model is None:
            return {"objects": [], "error": "Model not loaded"}
        
        try:
            results = self.model(frame, conf=self.confidence_threshold, verbose=False)
            detections = []
            
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = float(box.conf[0].cpu().numpy())
                        class_id = int(box.cls[0].cpu().numpy())
                        class_name = self.classes[class_id]
                        
                        bbox = [int(x1), int(y1), int(x2-x1), int(y2-y1)]
                        
                        detections.append({
                            "class": class_name,
                            "class_id": class_id,
                            "bbox": bbox,
                            "confidence": round(confidence, 3),
                            "center": [int(x1 + (x2-x1)/2), int(y1 + (y2-y1)/2)]
                        })
            
            # Group detections by class
            class_counts = {}
            for det in detections:
                class_name = det["class"]
                class_counts[class_name] = class_counts.get(class_name, 0) + 1
            
            return {
                "objects": detections,
                "class_counts": class_counts,
                "total_objects": len(detections),
                "timestamp": datetime.now().isoformat(),
                "frame_shape": frame.shape,
                "model_type": "specific_waste_classification"
            }
            
        except Exception as e:
            return {"objects": [], "error": str(e)}
    
    def get_recycling_info(self, class_name: str) -> Dict:
        """Get recycling information for specific waste types"""
        recycling_info = {
            'plastic': {
                'recyclable': True,
                'bin_type': 'Recycling Bin',
                'notes': 'Check recycling number, clean containers',
                'action': 'recycle'
            },
            'paper': {
                'recyclable': True,
                'bin_type': 'Paper Recycling',
                'notes': 'Remove staples, avoid wet paper',
                'action': 'recycle'
            },
            'cardboard': {
                'recyclable': True,
                'bin_type': 'Recycling Bin',
                'notes': 'Flatten boxes, remove tape',
                'action': 'recycle'
            },
            'glass': {
                'recyclable': True,
                'bin_type': 'Glass Recycling',
                'notes': 'Rinse containers, separate by color',
                'action': 'recycle'
            },
            'metal': {
                'recyclable': True,
                'bin_type': 'Metal Recycling',
                'notes': 'Clean cans, separate aluminum/steel',
                'action': 'recycle'
            },
            'trash': {
                'recyclable': False,
                'bin_type': 'General Waste',
                'notes': 'Non-recyclable waste',
                'action': 'dispose'
            },
            'dirt': {
                'recyclable': False,
                'bin_type': 'Compost/Garden',
                'notes': 'Can be composted if organic',
                'action': 'clean'
            }
        }
        
        return recycling_info.get(class_name, {
            'recyclable': False,
            'bin_type': 'Unknown',
            'notes': 'Classification uncertain',
            'action': 'inspect'
        })

# ============================================================================
# 3. ENHANCED DECISION MAKER FOR SPECIFIC ACTIONS
# ============================================================================

class SpecificDecisionMaker:
    """Makes specific decisions based on waste type detection"""
    
    def __init__(self):
        # Priority: 1=highest, 5=lowest
        self.action_priority = {
            'trash': 1,      # Highest priority - general waste
            'plastic': 2,    # Recyclable - high priority
            'glass': 2,      # Recyclable - high priority  
            'metal': 2,      # Recyclable - high priority
            'paper': 3,      # Recyclable but lower priority
            'cardboard': 3,  # Recyclable but lower priority
            'dirt': 4        # Lowest priority - cleaning
        }
    
    def make_specific_decision(self, detections: Dict) -> Dict:
        """Make decisions based on specific waste types detected"""
        if not detections.get("objects"):
            return {
                "decision": "none",
                "target_class": None,
                "target_bbox": None,
                "message": "No objects detected",
                "recycling_info": None
            }
        
        objects = detections["objects"]
        
        # Sort by priority and confidence
        objects_with_priority = [
            (self.action_priority.get(obj["class"], 999), -obj["confidence"], obj) 
            for obj in objects
        ]
        objects_with_priority.sort()
        target_obj = objects_with_priority[0][2]
        
        # Get recycling information
        detector = SpecificWasteDetector("dummy", 0.5)  # Just for recycling info
        recycling_info = detector.get_recycling_info(target_obj["class"])
        
        # Determine action
        if recycling_info["action"] == "recycle":
            decision = "pick_and_recycle"
            message = f"Pick up {target_obj['class']} and place in {recycling_info['bin_type']}"
        elif recycling_info["action"] == "dispose":
            decision = "pick_and_dispose"
            message = f"Pick up {target_obj['class']} and dispose in {recycling_info['bin_type']}"
        elif recycling_info["action"] == "clean":
            decision = "clean"
            message = f"Clean {target_obj['class']} area"
        else:
            decision = "inspect"
            message = f"Inspect {target_obj['class']} for proper handling"
        
        return {
            "decision": decision,
            "target_class": target_obj["class"],
            "target_bbox": target_obj["bbox"],
            "confidence": target_obj["confidence"],
            "message": message,
            "recycling_info": recycling_info,
            "total_objects": len(objects),
            "class_distribution": detections.get("class_counts", {})
        }

# ============================================================================
# 4. COMPLETE SYSTEM WITH SPECIFIC CLASSIFICATION
# ============================================================================

class SpecificWasteRobotAI:
    """Complete system for specific waste type classification and handling"""
    
    def __init__(self, model_path: str = None, confidence_threshold: float = 0.5):
        if model_path:
            self.detector = SpecificWasteDetector(model_path, confidence_threshold)
        else:
            self.detector = None
        self.decision_maker = SpecificDecisionMaker()
        
    def setup_complete_pipeline(self, dirt_images_folder: str = None):
        """Setup the complete pipeline with specific waste classification"""
        print("🚀 Setting up Specific Waste Classification Pipeline")
        print("=" * 60)
        
        processor = SpecificTrashNetProcessor()
        trashnet_data = processor.download_trashnet()
        if trashnet_data is None:
            print("❌ Failed to process dataset. Exiting.")
            return None
            
        dataset_yaml = processor.convert_to_yolo_format(trashnet_data)
        if dataset_yaml is None:
            print("❌ Failed to create dataset configuration. Exiting.")
            return None
        
        if dirt_images_folder:
            processor.add_dirt_images(dirt_images_folder)
        
        # Use TransferLearningTrainer from original code
        from ultralytics import YOLO
        
        print("\n🎓 Starting transfer learning training...")
        model = YOLO('yolov8s.pt')  # Load pre-trained model
        
        results = model.train(
            data=dataset_yaml,
            epochs=50,
            imgsz=640,
            batch=8,
            name='specific_waste_classification',
            project='runs/detect',
            patience=20
        )
        
        best_model = f"runs/detect/specific_waste_classification/weights/best.pt"
        self.detector = SpecificWasteDetector(best_model)
        
        print("\n✅ Complete pipeline setup finished!")
        return best_model
    
    def run_specific_detection(self, source: str = 0):
        """Run detection with specific waste classification"""
        if self.detector is None:
            print("❌ No detector loaded. Run setup_complete_pipeline() first.")
            return
        
        cap = cv2.VideoCapture(source)
        if not cap.isOpened():
            print(f"❌ Could not open source: {source}")
            return
        
        print("🎥 Starting specific waste type detection")
        print("📊 Press 'q' to quit, 's' to save analysis, 'i' for recycling info")
        
        frame_count = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            detections = self.detector.detect_specific_waste(frame)
            decision = self.decision_maker.make_specific_decision(detections)
            
            vis_frame = self._visualize_specific_detection(frame, detections, decision)
            cv2.imshow('Specific Waste Classification', vis_frame)
            
            if detections["objects"]:
                class_counts = detections.get("class_counts", {})
                counts_str = ", ".join([f"{k}: {v}" for k, v in class_counts.items()])
                print(f"Frame {frame_count}: [{counts_str}] | Action: {decision['decision']}")
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                self._save_specific_analysis(frame, detections, decision, frame_count)
            elif key == ord('i'):
                self._print_recycling_info(detections)
            
            frame_count += 1
        
        cap.release()
        cv2.destroyAllWindows()
    
    def _visualize_specific_detection(self, frame, detections, decision):
        """Visualize detections with specific waste type information"""
        vis_frame = frame.copy()
        
        for obj in detections.get("objects", []):
            x, y, w, h = obj["bbox"]
            class_name = obj["class"]
            confidence = obj["confidence"]
            color = self.detector.colors.get(class_name, (255, 255, 255))
            
            # Draw bounding box
            cv2.rectangle(vis_frame, (x, y), (x + w, y + h), color, 2)
            
            # Draw label with recycling info
            recycling_info = self.detector.get_recycling_info(class_name)
            recyclable = "♻️" if recycling_info["recyclable"] else "🗑️"
            label = f"{recyclable} {class_name}: {confidence:.3f}"
            
            cv2.putText(vis_frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # Draw class counts
        class_counts = detections.get("class_counts", {})
        y_offset = 30
        cv2.putText(vis_frame, "Detected Classes:", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        for class_name, count in class_counts.items():
            y_offset += 25
            color = self.detector.colors.get(class_name, (255, 255, 255))
            cv2.putText(vis_frame, f"{class_name}: {count}", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # Draw decision
        if decision["decision"] != "none":
            y_offset += 35
            cv2.putText(vis_frame, f"Action: {decision['message']}", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        return vis_frame
    
    def _print_recycling_info(self, detections):
        """Print detailed recycling information"""
        print("\n♻️  RECYCLING INFORMATION:")
        print("=" * 50)
        
        for obj in detections.get("objects", []):
            class_name = obj["class"]
            info = self.detector.get_recycling_info(class_name)
            
            print(f"\n📦 {class_name.upper()}:")
            print(f"   Recyclable: {'Yes' if info['recyclable'] else 'No'}")
            print(f"   Bin Type: {info['bin_type']}")
            print(f"   Notes: {info['notes']}")
            print(f"   Action: {info['action']}")
    
    def _save_specific_analysis(self, frame, detections, decision, frame_count):
        """Save detailed analysis of specific waste detection"""
        analysis = {
            "frame_number": frame_count,
            "timestamp": datetime.now().isoformat(),
            "detections": detections,
            "decision": decision,
            "model_type": "specific_waste_classification"
        }
        
        filename = f"specific_analysis_{frame_count}_{datetime.now().strftime('%H%M%S')}.json"
        with open(filename, 'w') as f:
            json.dump(analysis, f, indent=2)
        cv2.imwrite(f"specific_frame_{frame_count}.jpg", frame)
        print(f"💾 Saved specific analysis: {filename}")

# ============================================================================
# 5. MAIN DEMO FUNCTION
# ============================================================================

def demo_specific_waste_classification():
    """Demo the specific waste classification system"""
    print("🎯 SPECIFIC WASTE TYPE CLASSIFICATION DEMO")
    print("=" * 60)
    print("This system will classify:")
    print("✅ Plastic, Glass, Metal, Paper, Cardboard, Trash, Dirt")
    print("✅ Provide recycling guidance")
    print("✅ Make specific handling decisions")
    print()
    
    robot_ai = SpecificWasteRobotAI()
    dirt_folder = input("Enter path to dirt images folder (or press Enter to skip): ").strip()
    if not dirt_folder:
        dirt_folder = None
    
    try:
        model_path = robot_ai.setup_complete_pipeline(dirt_folder)
        if model_path:
            print(f"\n🎉 Setup completed! Model saved at: {model_path}")
            
            print("\nChoose detection mode:")
            print("1. Real-time camera detection")
            print("2. Process video file")
            print("3. Test on images")
            
            choice = input("Enter choice (1-3): ").strip()
            if choice == "1":
                robot_ai.run_specific_detection(0)
            elif choice == "2":
                video_path = input("Enter video file path: ").strip()
                robot_ai.run_specific_detection(video_path)
            elif choice == "3":
                test_specific_images(robot_ai)
        
    except KeyboardInterrupt:
        print("\n⏹️  Demo interrupted by user")
    except Exception as e:
        print(f"❌ Error in demo: {e}")

def test_specific_images(robot_ai):
    """Test specific waste classification on individual images"""
    print("🖼️  Specific Image Testing Mode")
    
    test_dir = Path("test_images")
    if not test_dir.exists():
        test_dir.mkdir()
        print(f"📁 Created {test_dir} folder. Add your test images there.")
        return
    
    image_files = list(test_dir.glob("*.jpg")) + list(test_dir.glob("*.png"))
    if not image_files:
        print("❌ No images found in test_images folder")
        return
    
    print(f"📷 Found {len(image_files)} images to test")
    for img_path in image_files:
        print(f"\n🔍 Testing: {img_path.name}")
        frame = cv2.imread(str(img_path))
        if frame is None:
            continue
        
        detections = robot_ai.detector.detect_specific_waste(frame)
        decision = robot_ai.decision_maker.make_specific_decision(detections)
        
        print(f"   Objects found: {detections.get('total_objects', 0)}")
        for class_name, count in detections.get("class_counts", {}).items():
            recycling_info = robot_ai.detector.get_recycling_info(class_name)
            status = "♻️" if recycling_info["recyclable"] else "🗑️"
            print(f"   - {status} {class_name}: {count}")
        
        if decision["decision"] != "none":
            print(f"   🤖 Action: {decision['message']}")
        
        vis_frame = robot_ai._visualize_specific_detection(frame, detections, decision)
        cv2.imshow(f'Specific Classification: {img_path.name}', vis_frame)
        key = cv2.waitKey(0) & 0xFF
        cv2.destroyAllWindows()
        if key == ord('q'):
            break

if __name__ == "__main__":
    demo_specific_waste_classification()
